why：CPU速度快，频率高，存储器（内存）读写速度慢，程序执行速度慢，CPU cache是为了弥补CPU和存储器的速度差距。
how：利用程序执行时的时间局部性和空间局部性（时空局部性），将内存数据缓存到CPU cache。CPU读取内存中的数据时，不是读取该数据的内存地址，而是读取一个连续的内存空间到缓存，
这个内存空间叫做一个内存块cache block（cache line），cache line一般为16个字节，当CPU需要访问数据时，首先访问CPU缓存，然后访问内存，如果要访问到的数据在缓存中，就命中，提高了数据
的访问速度。
what：读写策略，l1cache,l2cache,l3cache,缓存越大，速度越慢。
应用：
（1）数组和链表的遍历时间复杂度。
数组在内存中是连续的内存空间，链表是非连续的，因此数组可以利用CPU缓存提高遍历速度，链表却不行。
（2）对于二维数组的循环，如果数组按照行优先存储，则在遍历过程中，外层循环用行，内层循环用列，可充分利用空间局部性，提高程序读取速度。
相关：
LRU缓存替换策略
Branch Prediction（在程序的执行过程中，编译器会预判分支，预判错误的话会返回重新计算，增加了程序执行时间）

CPU缓存和分支预测的设计在本质上都是为了舒缓冯诺依曼计算机架构的瓶颈，CPU是控制器和运算器的实现，RAM内存是存储器的实现，CPU速度快，存储器读写速度慢，为了弥补速度上的差异，就有了CPU缓存和分支预测。
